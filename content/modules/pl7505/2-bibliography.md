---
title: "Bibliography Activity"
metaTitle: "Setting up a bibliography"
metaDescription: "This activity was focused around getting us a bit up to speed on academic citation and the different journal resources we had available."
---

## Introduction

There has been a surge in interest and investment in artificial intelligence (AI) across industries, and security-focused institutions are no exception. I compiled a list looking at legal, social science, and policy implications of AI, including a central book in driving how we can consider the end stages of the artificial intelligence development arc. I conclude with some thoughts on the reading and some areas where I would like to explore further.

## Bibliography

Bostrom, N. 2017./Superintelligence/. Dunod.
This book is a fairly foundational text on ways of THINKING about Artificial Intelligence, providing hints and tools for engaging with a technology that is arguably emergent.

Bode, I. and Huelss, H. 2018. Autonomous weapons systems and changing norms in international relations./Review of International Studies/ 44(3), pp. 393–413.
This article takes a constructivist lens to the development and application of Autonomous Weapon Systems (AWS) in contemporary conflict, and argues that there are two sets of norms at play in the AWS debate: one which exists that the legal and policy level in determining international norms around autonomous weapons use, and another which is the practical norms established at the operational level.

Crootof, R. 2015. The Killer Robots Are Here: Legal and Policy Implications./Cardoza Law Review/ 36, p. 80.
This article provides.a great definition for autonomous weapons systems as “a weapon system that, based on conclusions derived from gathered information and preprogrammed constraints, is capable of independently selecting and engaging targets.” (Crootof 2015, p.1837) Similar to Bode and Huelss’ argument, she argues that the use of Autonomous Weapon Systems in an operational context has made pre-emptive attempts to regulate their use moot. However, despite the genie being out of the bottle for autonomous weapon systems, there remains an opportunity to impose limits and set standards at the international level.

Horowitz, M.C. 2018. Artificial Intelligence, International Competition, and the Balance of Power./Texas National Security Review/ 1(3), p. 22.
Just a quick note on this journal: it is a relatively new national security journal out of the University of Texas and the War on the Rocks community. Overall, this article provided a good overview of AI in the defence context, and established its development and appropriate application as potentially the next deciding factor in great power conflict. This latter part — the appropriate application — is significant, as the article argues that the application of AI by a military and civilian bureaucracy could be fraught with challenges, citing the example of the Royal Navy’s failure to appropriately activate the strategic advantage aircraft carriers provided in dominating a given battlespace. (Horowitz 2018, p44)

Kania, E.B. 2017./Battlefield Singularity: Artificial Intelligence, Military Revolution, and China’s Future Military Power/. Center for a New American Security.
This is a report by the CNAS think tank in Washington DC which I thought was a good addition to this group. Specifically, this report did a good job of collating and translating current affairs and journal articles that would otherwise be inaccessible to a non-Mandarin speaking readers. The report lays out the observable actions that China is taking to dominate the AI debate as articulated in Horowitz 2018, shifting the balance of power toward China’s favour. Specifically, the frame the opportunity as unleashing a singularity on the battlefield, where autonomous and AI inflected systems overtake the cognitive capacity of human operators in combat. (Kania 2017, p5). This latter point reminds me of John Boyd’s OODA loop theory (as described by Osinga, F. 2007./Science, Strategy, and War: The Strategic Theory of John Boyd/), which establishes that the the combatant that can move more quickly through an Observe-Orient-Decide-Act loop will prevail.

## Summary

I want to establish a good starting reader for thinking about AI in the security context. Looking at how use of a technology can out pace our thinking about a technology, I believe we also need to consider how norm creation and creativity around technology is recursive: the more we use a thing, the better we understand its use, the more creative (or calcified) we might be in its application.

Similarly, understanding how different international actors — especially the United States and China — are considering their AI investments and strategies should serve as a fantastic frame for analysis and something I’d be curious to explore further.

To build on the above, I would also explore the following:

- Given more articles, I would have included some work by Noel Sharkey, a prominent AI/Robotics researcher who also founded the International Committee for Robot Arms Control and the Campaign for Killed Robots. I would have presented some counters to his work, eg. Ronald Arkin (they have debated in the past, eg: [‘Killer robots’ to be debated at UN - BBC News](https://www.bbc.com/news/technology-27343076) )
- I think we are missing a conversation around the accessibility to this technology at the non-state level. Many machine learning toolkits are open source, can be implemented at a small scale (i.e. embedded), and are frankly trivial to implement (I havedone so myself, implementing a prediction algorithm for train delays in San Francisco). Ultimately, I believe we need to do more investigation around the use of “smart” machines in asymmetric warfare situations, such as the use of robotic guns in Syria ( [Syria and Iraq Are Incubators for Remote-Controlled Guns](https://medium.com/war-is-boring/syria-and-iraq-are-incubators-for-remote-controlled-guns-27ce6004ab1f) ). This is a topic area I am quite interested in.
